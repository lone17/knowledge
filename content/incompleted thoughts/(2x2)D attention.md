---
aliases: 
tags: 
created: 2024-01-23 17:30 PM +07:00
modified: 2024-12-01 16:22 PM +07:00
---
#idea

- for images, why not make the attention 4D ?
- is there a way to exploit spatial relation with this approach
- even better, for n-d data, can use nxn-d attention using the same idea as above ?