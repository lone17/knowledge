---
aliases: 
tags: 
modified: 2024-11-30 17:46 PM +07:00
created: 2024-01-31 00:58 AM +07:00
---
#thought 

Thoughts from reading [[The Bitter Lesson]]

what I can distil from the article is, we should model learning rather than model knowledge

quite align with my perspective, as I favour philomath over philosophy

However, there is one idea that I do not completely agree with, which is 

> We want AI agents that can discover like we can

I suppose the ineffectiveness of human-based approaches can be partly due to the fundamental differences between human and machine

researchers want to make something that is smart like human
so they fall to the fallacy of modelling the machine over human
and they try to embed human knowledge into the machine, expecting it to use such knowledge the way humans do

but it is unknown, and also unlikely, that how the machine works is similar to how the human mind works

we don't even know how the human mind works ([[The problem with modelling the human brain]]), so it's even less likely that we can model it correctly

Dijkstra had a similar perspective, saying [["the effort to use machines to try to mimic human reasoning is both foolish and dangerous"]].

as such, can the knowledge generated by one type of intelligence be used effectively by a different type of intelligence ?

what was discussed in the post hinted toward a negative answer

these days I'm leaning more toward the idea that the intelligence that the machine might develop is of a a different type than human intelligence
and we should change our mindset that there's one major intelligence that is of humans
and stop using human intelligence as the scale

we learnt that intelligence is multi-dimensional, but let us familiarize ourselves with the idea that there could be multiple (parallel) multi-dimensional intelligences
kinda like the idea of multiverse

so back to the original point of "We want AI agents that can discover like we can"

yes, we should model learning rather than knowledge, because different intelligences might produce and make use of different types of knowledge

but do we also want it to learn like we do ?
(and do we even understand how we learn ?)

a different intelligence might learn in a different way
I said "might" because that's up for debate
but I'm in the "yes" camp