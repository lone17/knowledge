---
aliases: 
tags: 
modified: 2024-08-15 15:49 PM +07:00
created: 2024-08-15 15:44 PM +07:00
---
#cs/ai/ml/nlp/llm/inference 
# what
- an optimization technique for inference that makes educated guess about future toke while decoding the current token.
# resources
- paper: [[2211.17192] Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192)
- [A Hitchhikerâ€™s Guide to Speculative Decoding | PyTorch](https://pytorch.org/blog/hitchhikers-guide-speculative-decoding/)