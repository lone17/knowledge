---
aliases: 
tags: 
created: 2024-02-15 05:27 AM +07:00
modified: 2024-09-10 23:58 PM +07:00
---
#cs/ai/ml/nlp/llm #cs/ai/ml/quantization #todo/read

# what
- A weight-only post-training quantization method that
	- achieves SoTA performance in extreme compression (<= 4 bits per weight)
# application
- I-quant in [[llama-cpp]] was inspired by [[QuIP]]
	- source: [SOTA 2-bit quants by ikawrakow · Pull Request #4773 · ggerganov/llama.cpp · GitHub](https://github.com/ggerganov/llama.cpp/pull/4773)
# resources
- repo https://github.com/Cornell-RelaxML/quip-sharp