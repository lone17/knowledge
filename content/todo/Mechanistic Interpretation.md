---
aliases: 
tags:
  - cs/ai/ml/theory
  - cs/ai/ml/nlp/llm
  - cs/ai/ml/modular-learning
  - cs/ai/ml/mechanistic-intepretation
created: 2024-10-24 15:23 PM +07:00
modified: 2024-11-22 15:06 PM +07:00
---
> This is the master note for Mechanistic Interpretation

# observations, hypothesis and findings
- [[Theory of activation space]]
- [[The effects of neural net layers on activation space]]
# literature
## papers
- [[Refusal in Language Models Is Mediated by a Single Direction]]
- [[Toy Models of Superposition]]
- [[The Linear Representation Hypothesis and the Geometry of Large Language Models]]
- [[Representation Engineering: A Top-Down Approach to AI Transparency]]
- [[Steering Language Models With Activation Engineering]]
- [[A Language Model's Guide Through Latent Space]]
- [[Linear Representations of Sentiment in Large Language Models]]
- [[Universal and Transferable Adversarial Attacks on Aligned Language Models]]
- [[Transformer Feed-Forward Layers Are Key-Value Memories]]
## articles
#todo/study 
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features) 
- [Transformer Circuits Thread](https://transformer-circuits.pub)
- [Thread: Circuits](https://distill.pub/2020/circuits/)